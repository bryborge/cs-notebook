# K-Nearest Neighbor (KNN)

## Summary

K-Nearest Neighbor Algorithm is used for classification and regression problems.  It's a lazy learning, parametric that
finds the closest data points (`k` neighbors) in the dataset to a given query point.  It then makes a prediction (in the
case of classification) or an average value (in the case of regression) of those neighbors.

| Advantages | Disadvantages |
|------------|---------------|
| No training phase | Computationally intensive |
| Versatile; can be used for both regression and classification problems | Must store all training data into memory |
| Adaptable; can handle multi-class classification and multi-output regression | Sensitive to irrelevant features |
